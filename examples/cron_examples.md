# Ejemplos de Uso del Servicio de Cron para Snapshots

Este documento proporciona ejemplos de cÃ³mo usar el servicio de cron para el scraping automÃ¡tico de assets y creaciÃ³n de snapshots.

## DescripciÃ³n del Servicio

El servicio de cron se ejecuta automÃ¡ticamente **todos los domingos a las 3:00 AM UTC** y realiza las siguientes tareas:

1. ğŸ” **Obtiene todos los assets vÃ¡lidos** con sus tipos de inversiÃ³n
2. ğŸ’° **Scrapea el precio actual** de cada asset usando la estrategia correcta (Cedears, Criptomonedas, Acciones)
3. ğŸ“Š **Actualiza el campo `lastPrice`** del asset para optimizar futuras consultas
4. ğŸ“¸ **Crea snapshots** para todos los holdings asociados a cada asset
5. ğŸ“ˆ **Calcula y actualiza las ganancias** (earnings) de cada holding

## Endpoints Disponibles

### 1. Obtener Estado del Cron

```bash
GET /api/admin/cron/status
Authorization: Bearer YOUR_API_KEY
```

**Respuesta:**

```json
{
  "status": "success",
  "message": "Estado del cron obtenido exitosamente",
  "data": {
    "running": true,
    "total_jobs": 1,
    "next_execution": "2024-03-17 03:00:00 UTC"
  }
}
```

### 2. Obtener PrÃ³xima EjecuciÃ³n

```bash
GET /api/admin/cron/next
Authorization: Bearer YOUR_API_KEY
```

**Respuesta:**

```json
{
  "status": "success",
  "message": "PrÃ³xima ejecuciÃ³n obtenida exitosamente",
  "data": {
    "next_execution": "2024-03-17 03:00:00 UTC",
    "timezone": "UTC",
    "cron_expression": "0 3 * * 0",
    "description": "Se ejecuta todos los domingos a las 3:00 AM UTC"
  }
}
```

### 3. Ejecutar Scraping Manual

```bash
POST /api/admin/cron/execute
Authorization: Bearer YOUR_API_KEY
```

**Respuesta:**

```json
{
  "status": "success",
  "message": "Scraping manual iniciado en segundo plano",
  "data": {
    "message": "El scraping se estÃ¡ ejecutando. Revisa los logs del servidor para ver el progreso."
  }
}
```

### 4. Obtener InformaciÃ³n General

```bash
GET /api/admin/cron/info
Authorization: Bearer YOUR_API_KEY
```

**Respuesta:**

```json
{
  "status": "success",
  "message": "InformaciÃ³n del servicio de cron",
  "data": {
    "service_name": "Weekly Asset Scraping Service",
    "description": "Servicio que scrapea precios de assets y crea snapshots de holdings cada domingo",
    "schedule": "Domingos a las 3:00 AM UTC",
    "cron_expression": "0 3 * * 0",
    "status": {
      "running": true,
      "total_jobs": 1,
      "next_execution": "2024-03-17 03:00:00 UTC"
    },
    "next_execution": "2024-03-17 03:00:00 UTC",
    "features": [
      "Scraping automÃ¡tico de precios de assets",
      "ActualizaciÃ³n del campo lastPrice para optimizaciÃ³n",
      "CreaciÃ³n de snapshots para todos los holdings",
      "CÃ¡lculo automÃ¡tico de earnings",
      "Logging detallado del proceso",
      "EjecuciÃ³n manual via API"
    ],
    "endpoints": [
      {
        "method": "GET",
        "path": "/api/admin/cron/status",
        "description": "Obtener estado del servicio de cron"
      },
      {
        "method": "GET",
        "path": "/api/admin/cron/next",
        "description": "Obtener prÃ³xima ejecuciÃ³n programada"
      },
      {
        "method": "POST",
        "path": "/api/admin/cron/execute",
        "description": "Ejecutar scraping manual"
      },
      {
        "method": "GET",
        "path": "/api/admin/cron/info",
        "description": "Obtener informaciÃ³n general del servicio"
      }
    ]
  }
}
```

## Ejemplos con cURL

### Obtener estado del cron

```bash
curl -X GET "http://localhost:3000/api/admin/cron/status" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json"
```

### Ejecutar scraping manual

```bash
curl -X POST "http://localhost:3000/api/admin/cron/execute" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json"
```

### Obtener informaciÃ³n completa

```bash
curl -X GET "http://localhost:3000/api/admin/cron/info" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json"
```

## Logs del Servidor

Cuando el cron se ejecuta, verÃ¡s logs similares a estos en el servidor:

```
2024-03-17 03:00:00 ğŸš€ Iniciando scraping semanal de assets...
2024-03-17 03:00:00 ğŸ“Š Procesando 15 assets...
2024-03-17 03:00:01 ğŸ” Procesando asset: AAPL (AAPL)
2024-03-17 03:00:02 ğŸ’° Precio scrapeado para AAPL (AAPL): 150.25 USD
2024-03-17 03:00:02 ğŸ“¸ Creando 3 snapshots para asset AAPL (AAPL)
2024-03-17 03:00:02 ğŸ“ˆ Earnings actualizados para holding abc-123: 25.50 (2.15%)
2024-03-17 03:00:02 âœ… Asset procesado exitosamente: AAPL (AAPL) - Precio: 150.25
...
2024-03-17 03:02:30 ğŸ Scraping semanal completado en 2m30s - Ã‰xitos: 14, Errores: 1
```

## Optimizaciones Implementadas

### 1. **Campo `lastPrice` en Assets**

- Se actualiza con cada scraping para evitar mÃºltiples consultas
- Permite obtener el Ãºltimo precio conocido sin hacer scraping

### 2. **Pausa entre Requests**

- 200ms entre cada asset para ser respetuosos con los servidores
- Evita ser bloqueado por rate limiting

### 3. **Manejo de Errores**

- ContinÃºa procesando otros assets si uno falla
- Logging detallado de errores y Ã©xitos

### 4. **CÃ¡lculo AutomÃ¡tico de Earnings**

- Compara con el snapshot anterior para calcular ganancias
- Actualiza tanto earnings absolutos como relativos (%)

## Consideraciones de Horario

- **Horario programado**: Domingos 3:00 AM UTC
- **RazÃ³n**: Minimiza impacto en horarios de trading
- **DuraciÃ³n estimada**: 2-5 minutos dependiendo del nÃºmero de assets

## Monitoreo y Troubleshooting

### Verificar si el cron estÃ¡ funcionando:

```bash
curl -X GET "http://localhost:3000/api/admin/cron/status" \
  -H "Authorization: Bearer YOUR_API_KEY"
```

### Ejecutar manualmente para testing:

```bash
curl -X POST "http://localhost:3000/api/admin/cron/execute" \
  -H "Authorization: Bearer YOUR_API_KEY"
```

### Revisar logs del servidor:

```bash
docker-compose logs -f app
```

## Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CronService   â”‚â”€â”€â”€â–¶â”‚ ScrapingService â”‚â”€â”€â”€â–¶â”‚   Strategies    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Assets      â”‚    â”‚    Holdings     â”‚    â”‚   Yahoo Finance â”‚
â”‚   (lastPrice)   â”‚    â”‚   (earnings)    â”‚    â”‚   Other Sources â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚
         â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Snapshots     â”‚    â”‚   Database      â”‚
â”‚   (historical)  â”‚    â”‚   (persistent)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
